{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGXkRPlIS3X5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "W0LGxNyqS3YB",
    "outputId": "74fa521e-2c6e-4dfd-e342-6fb2e2d5fa7f"
   },
   "outputs": [],
   "source": [
    "NCLASSES = 2\n",
    "HEIGHT = 70\n",
    "WIDTH = 70\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DATA_SET_COUNT = 27558\n",
    "TEST_SET_COUNT = (DATA_SET_COUNT)*0.2\n",
    "TRAIN_SET_COUNT = (DATA_SET_COUNT) * 0.6\n",
    "VAL_SET_COUNT = (DATA_SET_COUNT) * 0.2\n",
    "print(TEST_SET_COUNT,TRAIN_SET_COUNT, VAL_SET_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rwA_KFLS3YG"
   },
   "source": [
    "Auxiliary function for loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eHnMbp0S3YH"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [WIDTH, HEIGHT])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HD3MC5UvS3YK"
   },
   "source": [
    "Load the dataset, replace the path with your own location of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "vbXdWj8QS3YM",
    "outputId": "465dd148-b077-4e80-cd86-1ad8a77094de"
   },
   "outputs": [],
   "source": [
    "#data_dir = pathlib.Path('C:/Users/paulo/OneDrive/Ambiente de Trabalho/Escola/Apendizagem automatica 2/Trabalho/AA2/input/cell_images')\n",
    "data_dir = pathlib.Path('drive/My Drive/cell_images')\n",
    "\n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#listset = tf.data.Dataset.list_files(\"C:/Users/paulo/OneDrive/Ambiente de Trabalho/Escola/Apendizagem automatica 2/Trabalho/AA2/input/cell_images/*/*.png\")\n",
    "listset = tf.data.Dataset.list_files(\"drive/My Drive/cell_images/*/*.png\")\n",
    "print(listset)\n",
    "\n",
    "\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXhK_4evS3YR"
   },
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3REuj_oS3YR"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/image\n",
    "#https://www.tensorflow.org/addons/api_docs/python/tfa/image\n",
    "\n",
    "#pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def process_image(image, label):\n",
    "    \n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    delta = tf.random.uniform(shape=(), minval=0.01, maxval=1) * 0.5\n",
    "    lower_saturation = 0.9 + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.2\n",
    "    upper_saturation = lower_saturation + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.2\n",
    "    lower_value = 0.9 + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.3\n",
    "    upper_value = lower_value + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.4\n",
    "    image = tfa.image.random_hsv_in_yiq(image, 0.3, 0.8, 1.1, 0.9, 1.3)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    image = tf.clip_by_value(tf.image.adjust_brightness(image, -0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def rotate_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    r = tf.random.uniform(shape=(), minval=0, maxval=360)\n",
    "    image = tfa.image.rotate(image, r)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def translate_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    rx = tf.random.uniform(shape=(), minval=0, maxval=1) * 14 - 7\n",
    "    ry = tf.random.uniform(shape=(), minval=0, maxval=1) * 14 - 7\n",
    "    image = tfa.image.translate(image, [rx, ry])\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def increase_contrast_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    image=tf.image.adjust_contrast(image,2)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def decrease_contrast_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    image=tf.image.adjust_contrast(image,0.6)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8k4rmnB8S3YV"
   },
   "source": [
    "Split the dataset into training, validation and tedt sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAEN0c6gS3YV"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "#dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "train_size = int(TRAIN_SET_COUNT)\n",
    "val_size = int(VAL_SET_COUNT)\n",
    "test_size= int(TEST_SET_COUNT)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "#-Data Augmentation\n",
    "'''\n",
    "d1= train_dataset.map(increase_contrast_image,num_parallel_calls=AUTOTUNE)\n",
    "d2= train_dataset.map(rotate_image,num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "NUM_MAPS_DATA_AUGMENT=3\n",
    "train_size=train_size*NUM_MAPS_DATA_AUGMENT\n",
    "\n",
    "train_dataset=train_dataset.concatenate(d1)\n",
    "train_dataset=train_dataset.concatenate(d2)\n",
    "#----\n",
    "'''\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size = train_size)\n",
    "train_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat();\n",
    "\n",
    "test_dataset = dataset.skip(train_size)\n",
    "test_dataset = test_dataset.take(test_size)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = train_size)\n",
    "test_dataset = test_dataset.batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = dataset.skip(train_size+test_size)\n",
    "val_dataset = val_dataset.cache()\n",
    "val_dataset = val_dataset.batch(batch_size=BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.repeat();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ts-ZoddMS3YZ"
   },
   "source": [
    "Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MEa2ffJS3Ya"
   },
   "outputs": [],
   "source": [
    "testset = test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGpPUEVDS3Ye"
   },
   "source": [
    "Primeiros resultados com 30 epocas:\n",
    "    Resultados -> [0.09822106476054887, 0.9724188]\n",
    "    \n",
    "    Resultados -> [0.09970240995915057, 0.9771366]\n",
    "    \n",
    "    Resultados -> [0.09709152765370195, 0.97913265]\n",
    "\n",
    "OS graficos do treino tem muitos altos e baixos. vou tentar reduzir o step de 0.001 para 0.0005 aver se ajuda.\n",
    "\n",
    "Como o número de epocas nao parece ter afetado, vou voltar a usar 20 epocas.\n",
    "\n",
    "Resultados:\n",
    "    \n",
    "    Resultados -> [0.07556610100638832, 0.97913265]\n",
    "    \n",
    "    Resultados -> [0.11845710180743398, 0.97822535]\n",
    "    \n",
    "    Resultados -> [0.11034344812033152, 0.9831247]\n",
    "    \n",
    "Parece que melhorou. \n",
    "\n",
    "Vou aumentar a complexidade da rede depois do flatten. Vou por 512 256 128\n",
    "\n",
    "Resultados -> [0.11262756224884517, 0.97749954]\n",
    "\n",
    "Resultados -> [0.112837254023314, 0.9825803]\n",
    "\n",
    "Resultados -> [0.1579071757994804, 0.9818545]\n",
    "\n",
    "Não consigo perceber se melhorou ou não. Vou aumentar a complexidade das camadas conv2d a ver o que acontece. Ficou 256 128 64\n",
    "\n",
    "Resultados -> [0.09519005841656314, 0.97913265]\n",
    "\n",
    "Resultados -> [0.1559975825278033, 0.979677]\n",
    "\n",
    "Resultados -> [0.12951020138670086, 0.9833061]\n",
    "\n",
    "Vou correr mais uma vez para ver melhor os resultados.\n",
    "\n",
    "Resultados -> [0.13078563809401567, 0.97659224]\n",
    "\n",
    "Resultados -> [0.10909477567710346, 0.9840319]\n",
    "\n",
    "Resultados -> [0.1473225694302675, 0.9825803]\n",
    "\n",
    "Vou fazer data augmentation para ver se melhora. Dupliquei o tamanho do dataset, usando uma função para rodar as imagens, e outra para aumentar o contraste. Assim força a rede a ignorar a orientação das celulas e força a rede a focar-se na diferença de cores entre infetada e nao infetada.\n",
    "\n",
    "Resultados -> [0.1550383184648878, 0.95717657]\n",
    "\n",
    "Resultados -> [0.11947062133536862, 0.9664308]\n",
    "\n",
    "Resultados -> [0.1277277860857783, 0.96842676]\n",
    "\n",
    "Ficou pior. Vou tentar apenas com um dos maps de cada vez. Primeiro vou tentar com o aumentar contrast.\n",
    "\n",
    "Resultados -> [0.20363568402073115, 0.93776083]\n",
    "\n",
    "Resultados -> [0.24657452397038884, 0.9609871]\n",
    "\n",
    "Resultados -> [0.2891723330340764, 0.9468336]\n",
    "\n",
    "Ficou bastante pior. Vou testar com o outro.\n",
    "\n",
    "Resultados -> [0.23375302097542114, 0.96407187]\n",
    "\n",
    "Resultados -> [0.4722976528172342, 0.95481765]\n",
    "\n",
    "Resultados -> [0.5312820033113527, 0.9499183]\n",
    "\n",
    "Tanto o rotation, como o aumentar contraste poe os resultados piores.\n",
    "\n",
    "Vou testar com os 3 juntos a ver. Aumentar contraste rodar e as imagens normais.\n",
    "\n",
    "Resultados -> [0.08983509639221529, 0.9695155]\n",
    "\n",
    "Resultados -> [0.06904044048322332, 0.9804028]\n",
    "\n",
    "Resultados -> [0.05812383999219003, 0.9849392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "XfptI9gZS3Yf",
    "outputId": "913b0406-5bd4-4295-ec77-0fd013509116"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_size = int(TRAIN_SET_COUNT)\n",
    "val_size = int(VAL_SET_COUNT)\n",
    "test_size= int(TEST_SET_COUNT)\n",
    "\n",
    "def cnn55D3L2FC(classCount, imgSize, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same',input_shape=(imgSize, imgSize, channels),activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu') ) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu') )   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "\n",
    "    model.add(Dense(classCount, activation='softmax'))\n",
    "\n",
    "    \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ metrics.categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "model = cnn55D3L2FC(2, 70, 3)\n",
    "\n",
    "outs=[];\n",
    "for x in range(3):\n",
    "\n",
    "    history = model.fit(train_dataset, steps_per_epoch = train_size/BATCH_SIZE,epochs=20, validation_data = val_dataset, validation_steps= val_size/BATCH_SIZE, verbose=1)\n",
    "\n",
    "    var=model.evaluate(test_dataset)\n",
    "    outs.append(\"Resultados -> \"+ str(var))\n",
    "    \n",
    "for s in outs:\n",
    "    print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2yTtCezS3Yi"
   },
   "outputs": [],
   "source": [
    "print(model.summary())\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvmC4v4cS3Yl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
