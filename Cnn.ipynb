{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5511.6 16534.8 5511.6\n"
     ]
    }
   ],
   "source": [
    "NCLASSES = 2\n",
    "HEIGHT = 70\n",
    "WIDTH = 70\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DATA_SET_COUNT = 27558\n",
    "TEST_SET_COUNT = (DATA_SET_COUNT)*0.2\n",
    "TRAIN_SET_COUNT = (DATA_SET_COUNT) * 0.6\n",
    "VAL_SET_COUNT = (DATA_SET_COUNT) * 0.2\n",
    "print(TEST_SET_COUNT,TRAIN_SET_COUNT, VAL_SET_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function for loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [WIDTH, HEIGHT])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset, replace the path with your own location of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('C:/Users/paulo/OneDrive/Ambiente de Trabalho/Escola/Apendizagem automatica 2/Trabalho/AA2/input/cell_images')\n",
    "#data_dir = pathlib.Path(r'C:\\Users\\Nuno\\Desktop\\trabalhoAA2\\input\\cell_images')\n",
    "\n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"C:/Users/paulo/OneDrive/Ambiente de Trabalho/Escola/Apendizagem automatica 2/Trabalho/AA2/input/cell_images/*/*.png\")\n",
    "#listset = tf.data.Dataset.list_files(r\"C:\\Users\\Nuno\\Desktop\\trabalhoAA2\\input\\cell_images\\*\\*.png\")\n",
    "\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "## Acabou por não ser usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/image\n",
    "#https://www.tensorflow.org/addons/api_docs/python/tfa/image\n",
    "\n",
    "#pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def process_image(image, label):\n",
    "    \n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    delta = tf.random.uniform(shape=(), minval=0.01, maxval=1) * 0.5\n",
    "    lower_saturation = 0.9 + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.2\n",
    "    upper_saturation = lower_saturation + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.2\n",
    "    lower_value = 0.9 + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.3\n",
    "    upper_value = lower_value + tf.random.uniform(shape=(), minval=0, maxval=1) * 0.4\n",
    "    image = tfa.image.random_hsv_in_yiq(image, 0.3, 0.8, 1.1, 0.9, 1.3)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    image = tf.clip_by_value(tf.image.adjust_brightness(image, -0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def rotate_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    r = tf.random.uniform(shape=(), minval=0, maxval=360)\n",
    "    image = tfa.image.rotate(image, r)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def translate_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    rx = tf.random.uniform(shape=(), minval=0, maxval=1) * 14 - 7\n",
    "    ry = tf.random.uniform(shape=(), minval=0, maxval=1) * 14 - 7\n",
    "    image = tfa.image.translate(image, [rx, ry])\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def increase_contrast_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    image=tf.image.adjust_contrast(image,2)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label\n",
    "\n",
    "def decrease_contrast_image(image, label):\n",
    "    #image = tf.image.resize(image, (64,64))\n",
    "    \n",
    "    image=tf.image.adjust_contrast(image,0.6)\n",
    "    \n",
    "    #image = tf.image.resize(image, (32,32))\n",
    "    #image = tf.clip_by_value(tf.image.adjust_brightness(image, tf.random.uniform(shape=(), minval=0, maxval=1)-0.2),0,1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and tedt sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "#dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "train_size = int(TRAIN_SET_COUNT)\n",
    "val_size = int(VAL_SET_COUNT)\n",
    "test_size= int(TEST_SET_COUNT)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "#-Data Augmentation\n",
    "d1= train_dataset.map(increase_contrast_image,num_parallel_calls=AUTOTUNE)\n",
    "d2= train_dataset.map(rotate_image,num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "NUM_MAPS_DATA_AUGMENT=3\n",
    "train_size=train_size*NUM_MAPS_DATA_AUGMENT\n",
    "\n",
    "train_dataset=train_dataset.concatenate(d1)\n",
    "train_dataset=train_dataset.concatenate(d2)\n",
    "#----\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size = train_size)\n",
    "train_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat();\n",
    "\n",
    "test_dataset = dataset.skip(train_size)\n",
    "test_dataset = test_dataset.take(test_size)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = train_size)\n",
    "test_dataset = test_dataset.batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = dataset.skip(train_size+test_size)\n",
    "val_dataset = val_dataset.cache()\n",
    "val_dataset = val_dataset.batch(batch_size=BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.repeat();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Todos os treinos feitos são feitos com as imagens todas com tamanho 50x50 de modo a tornar o input igual para todas elas.\n",
    "- Primeiros resultados com 30 epocas:\n",
    "\n",
    "    Rede: learning rate - 0.001\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "    \n",
    "    Resultados -> [0.09822106476054887, 0.9724188]\n",
    "    \n",
    "    Resultados -> [0.09970240995915057, 0.9771366]\n",
    "    \n",
    "    Resultados -> [0.09709152765370195, 0.97913265]\n",
    "\n",
    "\n",
    "- OS graficos do treino tem muitos altos e baixos. vou tentar reduzir a learning rate de 0.001 para 0.0005 aver se ajuda.\n",
    "\n",
    "    Com o número de epocas a 30 não é possivel ver uma melhoria continua dos resultados, por isso, decidiu-se diminuir esse número para as 20, visto que parece ser necessário para chegar a bons resultados.\n",
    "\n",
    "    \n",
    "    Resultados -> [0.07556610100638832, 0.97913265]\n",
    "    \n",
    "    Resultados -> [0.11845710180743398, 0.97822535]\n",
    "    \n",
    "    Resultados -> [0.11034344812033152, 0.9831247]\n",
    "    \n",
    "    Estas alterações parecem ter dados melhores resultados, assim, este modelo vai se manter e qualquer alteração será feita no mesmo.\n",
    "\n",
    "- Agora vou experimentar aumentar a complexidade da rede depois do flatten.\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.11262756224884517, 0.97749954]\n",
    "\n",
    "    Resultados -> [0.112837254023314, 0.9825803]\n",
    "\n",
    "    Resultados -> [0.1579071757994804, 0.9818545]\n",
    "\n",
    "- Não é possivel perceber se o ultimo passo melhorou ou não. Vou mander a rede anterior e aumentar a complexidade das camadas conv2d a ver o que acontece. Ficou 256 128 64\n",
    "\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.09519005841656314, 0.97913265]\n",
    "\n",
    "    Resultados -> [0.1559975825278033, 0.979677]\n",
    "\n",
    "    Resultados -> [0.12951020138670086, 0.9833061]\n",
    "\n",
    "    Decidi correr mais uma vez para ter uma ideia melhor de qual a média de resultados.\n",
    "\n",
    "    Resultados -> [0.13078563809401567, 0.97659224]\n",
    "\n",
    "    Resultados -> [0.10909477567710346, 0.9840319]\n",
    "\n",
    "    Resultados -> [0.1473225694302675, 0.9825803]\n",
    "    \n",
    "    Parece que com este modelo conseguimos os melhores resultados até agora. Por isso vamos Manter o mesmo\n",
    "\n",
    "- Vou fazer data augmentation para ver se melhora os resultados.\n",
    "    Dupliquei o tamanho do dataset, usando uma função para rodar as imagens, e outra para aumentar o contraste. Assim força a rede a ignorar a orientação das celulas e força a rede a focar-se na diferença de cores entre infetada e nao infetada.\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.1550383184648878, 0.95717657]\n",
    "\n",
    "    Resultados -> [0.11947062133536862, 0.9664308]\n",
    "\n",
    "    Resultados -> [0.1277277860857783, 0.96842676]\n",
    "\n",
    "- Os resultados ficaram bastane piores por isso vou tentar apenas com um dos maps de cada vez. Primeiro vou tentar com o aumentar contrast.\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.20363568402073115, 0.93776083]\n",
    "\n",
    "    Resultados -> [0.24657452397038884, 0.9609871]\n",
    "\n",
    "    Resultados -> [0.2891723330340764, 0.9468336]\n",
    "\n",
    "- Mais uma vez, ficou ainda pior. Agora vou testar com o de rodar as imagens.\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.23375302097542114, 0.96407187]\n",
    "\n",
    "    Resultados -> [0.4722976528172342, 0.95481765]\n",
    "\n",
    "    Resultados -> [0.5312820033113527, 0.9499183]\n",
    "\n",
    "    Tanto o rotation, como o aumentar contraste poe os resultados piores.\n",
    "\n",
    "- Como uma ultima tentativa de usar data sugmentation vou testar com os 3 juntos a ver (Aumentar contraste rodar e as imagens normais).\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "\n",
    "    Resultados -> [0.08983509639221529, 0.9695155]\n",
    "\n",
    "    Resltados -> [0.06904044048322332, 0.9804028]\n",
    "\n",
    "    Resultados -> [0.05812383999219003, 0.9849392]\n",
    "    \n",
    "    Nesta ultima situação não é possivel ver nenhuma melhoria e o treino ficou muito mais lento devito a termos um dataset 3 vezes maior que o original. Deste modo, vai se abandonar o data augmentation visto que nao melhora os resultados e visto também que temos um dataset bastante grande.\n",
    "    \n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        conv2d(128)\n",
    "        conv2d(64)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "        \n",
    "- Ao longo de todo o processo de treinamento da rede existem zonas de dropout e maxpooling que não estão referidas nos modelos. Com isto podemos ter um modelo mais detalhado aqui:\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        dropout(0.3)\n",
    "        conv2d(128)\n",
    "        maxpooling(2,2)\n",
    "        dropout(0.3)\n",
    "        conv2d(64)\n",
    "        maxpooling(2,2)\n",
    "        dropout(0.3)\n",
    "        flattten()\n",
    "        Dense(512)\n",
    "        Dropout(0.3)\n",
    "        Dense(256)\n",
    "        Dense(128)\n",
    "    O dropout e o maxpooling sempre estiveram presentes desde o inicio da rede, mas para manter o modelo mais simples de escrever decidiu omitir-se dos modelos acima escritos mencionando apenas agora.\n",
    "    \n",
    "- Depois de alguns testes feitos(40x40, 30x30, 100x100) chegamos a um tamanho de imagens que parece dar melhores resultados que os 50x50. Juntamente com esta alteração de tamanhos alterou-se também a rede depois do flatten() ficando assim:\n",
    "    Rede: learning rate - 0.0005\n",
    "        conv2d(256)\n",
    "        dropout(0.3)\n",
    "        conv2d(128)\n",
    "        maxpooling(2,2)\n",
    "        dropout(0.3)\n",
    "        conv2d(64)\n",
    "        maxpooling(2,2)\n",
    "        dropout(0.3)\n",
    "        flattten()\n",
    "        Dense(128)\n",
    "        Dropout(0.3)\n",
    "        Dense(64)\n",
    "        \n",
    "    \n",
    "    Resultados -> [0.09002264992823836, 0.9700599]\n",
    "    Resultados -> [0.06715019416862109, 0.9847578]\n",
    "    Resultados -> [0.03985877299238524, 0.9891127]\n",
    "        \n",
    "- Agora vai ser feito uma função para optimizar hiper parametros, como o dropout e o learning rate.\n",
    "    \n",
    "    Resultado ([0.3, 0.3, 0.3, 0.3], 0.0005) ->[0.08301462591598834, 0.9707857]\n",
    "    \n",
    "    Resultado ([0.3, 0.3, 0.3, 0.3], 0.001) ->[0.09891370363598097, 0.96842676]\n",
    "    \n",
    "    Resultado ([0.3, 0.3, 0.3, 0.3], 0.002) ->[0.6930431999223081, 0.50807476]\n",
    "    \n",
    "    Resultado ([0.3, 0.3, 0.3, 0.3], 0.00025) ->[0.08059742877453652, 0.9727817]\n",
    "    \n",
    "    Resultado ([0.4, 0.4, 0.4, 0.4], 0.0005) ->[0.10650778054717304, 0.96770096]\n",
    "    \n",
    "    Resultado ([0.4, 0.4, 0.4, 0.4], 0.001) ->[0.1261667709022416, 0.9611686]\n",
    "    \n",
    "    Resultado ([0.4, 0.4, 0.4, 0.4], 0.002) ->[0.6931555774170539, 0.500998]\n",
    "    \n",
    "    Resultado ([0.4, 0.4, 0.4, 0.4], 0.00025) ->[0.10625480001286275, 0.9622573]\n",
    "    \n",
    "    Resultado ([0.2, 0.2, 0.2, 0.2], 0.0005) ->[0.07509214564554953, 0.97822535]\n",
    "    \n",
    "    Resultado ([0.2, 0.2, 0.2, 0.2], 0.001) ->[0.09360368248893519, 0.9700599]\n",
    "    \n",
    "    Resultado ([0.2, 0.2, 0.2, 0.2], 0.002) ->[0.13269870104860362, 0.9586282]\n",
    "    \n",
    "    Resultado ([0.2, 0.2, 0.2, 0.2], 0.00025) ->[0.056418394388609454, 0.981673]\n",
    "    \n",
    "    Estes treinos demoraram cerca de 12 horas a fazer e podemos observar que a melhor configuração é [0.2, 0.2, 0.2, 0.2], 0.00025 com cerca de 98.1% de accuracy. Estes valores podem variar bastante com mais treinos, mas considera-se este modelo o melhor até ao momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_size = int(TRAIN_SET_COUNT)\n",
    "val_size = int(VAL_SET_COUNT)\n",
    "test_size= int(TEST_SET_COUNT)\n",
    "\n",
    "def cnn55D3L2FC(classCount, imgSize, channels,dropouts,learning_rate):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same',input_shape=(imgSize, imgSize, channels),activation='relu'))\n",
    "    model.add(Dropout(dropouts[0]))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu') ) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropouts[1]))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu') )   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropouts[2]))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropouts[3]))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    \n",
    "\n",
    "    model.add(Dense(classCount, activation='softmax'))\n",
    "\n",
    "    #0.0005\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ metrics.categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "#model = cnn55D3L2FC(2, 70, 3)\n",
    "\n",
    "#outs=[];\n",
    "#for x in range(3):\n",
    "\n",
    " #   history = model.fit(train_dataset, steps_per_epoch = train_size/BATCH_SIZE,epochs=20, validation_data = val_dataset, validation_steps= val_size/BATCH_SIZE)\n",
    "\n",
    "  #  var=model.evaluate(test_dataset)\n",
    "   # outs.append(\"Resultados -> \"+ str(var))\n",
    "    \n",
    "#for s in outs:\n",
    " #   print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros\n",
    "- deve receber um array de arrays com varios dropouts cada elemento (array interior) tem de ter 4 valores para ele por na rede\n",
    "- deve tambem receber um array de learning rates\n",
    "vai testar todas as opções possiveis \n",
    "\n",
    "Exemplo:\n",
    "    opt_hiper([[0.3,0.3,0.3,0.3],[0.4,0.4,0.4,0.4],[0.2,0.2,0.2,0.2]],[0.0005,0.001,0.002,0.00025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 289s 560ms/step - loss: 0.4590 - categorical_accuracy: 0.7647 - val_loss: 0.2265 - val_categorical_accuracy: 0.9346\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 208s 401ms/step - loss: 0.1907 - categorical_accuracy: 0.9393 - val_loss: 0.1499 - val_categorical_accuracy: 0.9557\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 205s 397ms/step - loss: 0.1717 - categorical_accuracy: 0.9491 - val_loss: 0.1411 - val_categorical_accuracy: 0.9604\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 203s 394ms/step - loss: 0.1497 - categorical_accuracy: 0.9520 - val_loss: 0.1317 - val_categorical_accuracy: 0.9566\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 203s 392ms/step - loss: 0.1449 - categorical_accuracy: 0.9547 - val_loss: 0.1251 - val_categorical_accuracy: 0.9581\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 202s 390ms/step - loss: 0.1429 - categorical_accuracy: 0.9537 - val_loss: 0.1609 - val_categorical_accuracy: 0.9473\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 205s 396ms/step - loss: 0.1240 - categorical_accuracy: 0.9603 - val_loss: 0.1260 - val_categorical_accuracy: 0.9590\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 204s 395ms/step - loss: 0.1333 - categorical_accuracy: 0.9573 - val_loss: 0.1189 - val_categorical_accuracy: 0.9597\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 203s 392ms/step - loss: 0.1370 - categorical_accuracy: 0.9563 - val_loss: 0.1331 - val_categorical_accuracy: 0.9572\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 204s 395ms/step - loss: 0.1208 - categorical_accuracy: 0.9607 - val_loss: 0.1067 - val_categorical_accuracy: 0.9646\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 204s 394ms/step - loss: 0.1205 - categorical_accuracy: 0.9611 - val_loss: 0.1162 - val_categorical_accuracy: 0.9592\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 205s 396ms/step - loss: 0.1278 - categorical_accuracy: 0.9573 - val_loss: 0.1006 - val_categorical_accuracy: 0.9648\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 206s 398ms/step - loss: 0.1144 - categorical_accuracy: 0.9600 - val_loss: 0.1040 - val_categorical_accuracy: 0.9651\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 205s 396ms/step - loss: 0.1129 - categorical_accuracy: 0.9628 - val_loss: 0.1134 - val_categorical_accuracy: 0.9608\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 204s 394ms/step - loss: 0.1104 - categorical_accuracy: 0.9631 - val_loss: 0.0930 - val_categorical_accuracy: 0.9662\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 207s 401ms/step - loss: 0.1043 - categorical_accuracy: 0.9655 - val_loss: 0.1008 - val_categorical_accuracy: 0.9635\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 204s 395ms/step - loss: 0.1020 - categorical_accuracy: 0.9648 - val_loss: 0.1003 - val_categorical_accuracy: 0.9648\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 205s 396ms/step - loss: 0.1103 - categorical_accuracy: 0.9620 - val_loss: 0.0936 - val_categorical_accuracy: 0.9680\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 208s 402ms/step - loss: 0.0962 - categorical_accuracy: 0.9678 - val_loss: 0.0887 - val_categorical_accuracy: 0.9691\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 208s 401ms/step - loss: 0.0963 - categorical_accuracy: 0.9680 - val_loss: 0.0812 - val_categorical_accuracy: 0.9707\n",
      "173/173 [==============================] - 125s 724ms/step - loss: 0.0830 - categorical_accuracy: 0.9708\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 209s 404ms/step - loss: 0.7007 - categorical_accuracy: 0.5186 - val_loss: 0.6928 - val_categorical_accuracy: 0.5901\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 205s 396ms/step - loss: 0.6802 - categorical_accuracy: 0.5766 - val_loss: 0.6273 - val_categorical_accuracy: 0.6945\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 204s 395ms/step - loss: 0.3454 - categorical_accuracy: 0.8712 - val_loss: 0.2175 - val_categorical_accuracy: 0.9335\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 197s 380ms/step - loss: 0.1981 - categorical_accuracy: 0.9386 - val_loss: 0.1705 - val_categorical_accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 367ms/step - loss: 0.1805 - categorical_accuracy: 0.9438 - val_loss: 0.1381 - val_categorical_accuracy: 0.9594\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.1607 - categorical_accuracy: 0.9505 - val_loss: 0.1604 - val_categorical_accuracy: 0.9498\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1538 - categorical_accuracy: 0.9520 - val_loss: 0.1507 - val_categorical_accuracy: 0.9521\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1434 - categorical_accuracy: 0.9564 - val_loss: 0.1273 - val_categorical_accuracy: 0.9590\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1487 - categorical_accuracy: 0.9532 - val_loss: 0.1199 - val_categorical_accuracy: 0.9615\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1345 - categorical_accuracy: 0.9580 - val_loss: 0.1152 - val_categorical_accuracy: 0.9613\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1397 - categorical_accuracy: 0.9553 - val_loss: 0.1196 - val_categorical_accuracy: 0.9632\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1367 - categorical_accuracy: 0.9562 - val_loss: 0.1461 - val_categorical_accuracy: 0.9539\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1301 - categorical_accuracy: 0.9587 - val_loss: 0.1359 - val_categorical_accuracy: 0.9570\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1333 - categorical_accuracy: 0.9584 - val_loss: 0.1141 - val_categorical_accuracy: 0.9639\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1320 - categorical_accuracy: 0.9578 - val_loss: 0.1201 - val_categorical_accuracy: 0.9637\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.1194 - categorical_accuracy: 0.9604 - val_loss: 0.1171 - val_categorical_accuracy: 0.9621\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1241 - categorical_accuracy: 0.9600 - val_loss: 0.1199 - val_categorical_accuracy: 0.9574\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1265 - categorical_accuracy: 0.9590 - val_loss: 0.1094 - val_categorical_accuracy: 0.9630\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1199 - categorical_accuracy: 0.9605 - val_loss: 0.1043 - val_categorical_accuracy: 0.9648\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1116 - categorical_accuracy: 0.9629 - val_loss: 0.1015 - val_categorical_accuracy: 0.9655\n",
      "173/173 [==============================] - 111s 641ms/step - loss: 0.0989 - categorical_accuracy: 0.9684\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.7005 - categorical_accuracy: 0.5037 - val_loss: 0.6963 - val_categorical_accuracy: 0.5009\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6934 - categorical_accuracy: 0.5002 - val_loss: 0.6963 - val_categorical_accuracy: 0.4949\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.4945 - val_loss: 0.6963 - val_categorical_accuracy: 0.5034\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.6934 - categorical_accuracy: 0.4911 - val_loss: 0.6963 - val_categorical_accuracy: 0.4980\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.4956 - val_loss: 0.6964 - val_categorical_accuracy: 0.5014\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6931 - categorical_accuracy: 0.5064 - val_loss: 0.6969 - val_categorical_accuracy: 0.4960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.6932 - categorical_accuracy: 0.5008 - val_loss: 0.6963 - val_categorical_accuracy: 0.5049\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.5024 - val_loss: 0.6965 - val_categorical_accuracy: 0.4978\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6933 - categorical_accuracy: 0.4984 - val_loss: 0.6961 - val_categorical_accuracy: 0.5121\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6932 - categorical_accuracy: 0.5008 - val_loss: 0.6965 - val_categorical_accuracy: 0.4993\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.6932 - categorical_accuracy: 0.5048 - val_loss: 0.6963 - val_categorical_accuracy: 0.4998\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.5051 - val_loss: 0.6965 - val_categorical_accuracy: 0.4957\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.4998 - val_loss: 0.6961 - val_categorical_accuracy: 0.5105\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.4963 - val_loss: 0.6963 - val_categorical_accuracy: 0.4986\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6932 - categorical_accuracy: 0.5038 - val_loss: 0.6963 - val_categorical_accuracy: 0.5009\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.4992 - val_loss: 0.6963 - val_categorical_accuracy: 0.5043\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.6933 - categorical_accuracy: 0.4929 - val_loss: 0.6964 - val_categorical_accuracy: 0.4890\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.5021 - val_loss: 0.6964 - val_categorical_accuracy: 0.4995\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.5022 - val_loss: 0.6964 - val_categorical_accuracy: 0.4966\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.6931 - categorical_accuracy: 0.5084 - val_loss: 0.6967 - val_categorical_accuracy: 0.5014\n",
      "173/173 [==============================] - 110s 638ms/step - loss: 0.6930 - categorical_accuracy: 0.5081\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.4847 - categorical_accuracy: 0.7494 - val_loss: 0.2515 - val_categorical_accuracy: 0.9294\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.2410 - categorical_accuracy: 0.9250 - val_loss: 0.2239 - val_categorical_accuracy: 0.9270\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1781 - categorical_accuracy: 0.9427 - val_loss: 0.1532 - val_categorical_accuracy: 0.9518\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1494 - categorical_accuracy: 0.9524 - val_loss: 0.1363 - val_categorical_accuracy: 0.9581\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1523 - categorical_accuracy: 0.9500 - val_loss: 0.1383 - val_categorical_accuracy: 0.9520\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1456 - categorical_accuracy: 0.9539 - val_loss: 0.1392 - val_categorical_accuracy: 0.9514\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1305 - categorical_accuracy: 0.9564 - val_loss: 0.1257 - val_categorical_accuracy: 0.9568\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1366 - categorical_accuracy: 0.9559 - val_loss: 0.1107 - val_categorical_accuracy: 0.9612\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1275 - categorical_accuracy: 0.9592 - val_loss: 0.1143 - val_categorical_accuracy: 0.9594\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1185 - categorical_accuracy: 0.9595 - val_loss: 0.1061 - val_categorical_accuracy: 0.9632\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1178 - categorical_accuracy: 0.9614 - val_loss: 0.1086 - val_categorical_accuracy: 0.9651\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1174 - categorical_accuracy: 0.9615 - val_loss: 0.1138 - val_categorical_accuracy: 0.9585\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1050 - categorical_accuracy: 0.9631 - val_loss: 0.0979 - val_categorical_accuracy: 0.9637\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1103 - categorical_accuracy: 0.9631 - val_loss: 0.0973 - val_categorical_accuracy: 0.9678\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1027 - categorical_accuracy: 0.9643 - val_loss: 0.0842 - val_categorical_accuracy: 0.9716\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0975 - categorical_accuracy: 0.9664 - val_loss: 0.0820 - val_categorical_accuracy: 0.9713\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0988 - categorical_accuracy: 0.9654 - val_loss: 0.0825 - val_categorical_accuracy: 0.9707\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.0984 - categorical_accuracy: 0.9671 - val_loss: 0.1271 - val_categorical_accuracy: 0.9590\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.0865 - categorical_accuracy: 0.9717 - val_loss: 0.0808 - val_categorical_accuracy: 0.9727\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0861 - categorical_accuracy: 0.9700 - val_loss: 0.0785 - val_categorical_accuracy: 0.9743\n",
      "173/173 [==============================] - 112s 646ms/step - loss: 0.0806 - categorical_accuracy: 0.97281:05 - \n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.5542 - categorical_accuracy: 0.7020 - val_loss: 0.3042 - val_categorical_accuracy: 0.8983\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.2010 - categorical_accuracy: 0.9370 - val_loss: 0.1464 - val_categorical_accuracy: 0.9536\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1685 - categorical_accuracy: 0.9496 - val_loss: 0.1485 - val_categorical_accuracy: 0.9579\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1564 - categorical_accuracy: 0.9513 - val_loss: 0.1364 - val_categorical_accuracy: 0.9577\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1597 - categorical_accuracy: 0.9512 - val_loss: 0.1377 - val_categorical_accuracy: 0.9581\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1428 - categorical_accuracy: 0.9563 - val_loss: 0.1219 - val_categorical_accuracy: 0.9610\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1448 - categorical_accuracy: 0.9568 - val_loss: 0.1304 - val_categorical_accuracy: 0.9594\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1424 - categorical_accuracy: 0.9564 - val_loss: 0.1193 - val_categorical_accuracy: 0.9619\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1352 - categorical_accuracy: 0.9570 - val_loss: 0.1446 - val_categorical_accuracy: 0.9559\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1303 - categorical_accuracy: 0.9581 - val_loss: 0.1248 - val_categorical_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1279 - categorical_accuracy: 0.9600 - val_loss: 0.1233 - val_categorical_accuracy: 0.9603\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1299 - categorical_accuracy: 0.9585 - val_loss: 0.1375 - val_categorical_accuracy: 0.9556\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1198 - categorical_accuracy: 0.9622 - val_loss: 0.1178 - val_categorical_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1197 - categorical_accuracy: 0.9622 - val_loss: 0.1113 - val_categorical_accuracy: 0.9651\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1344 - categorical_accuracy: 0.9577 - val_loss: 0.1125 - val_categorical_accuracy: 0.9633\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1162 - categorical_accuracy: 0.9627 - val_loss: 0.1064 - val_categorical_accuracy: 0.9642\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1132 - categorical_accuracy: 0.9632 - val_loss: 0.1251 - val_categorical_accuracy: 0.9628\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1246 - categorical_accuracy: 0.9611 - val_loss: 0.1206 - val_categorical_accuracy: 0.9610\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 192s 371ms/step - loss: 0.1086 - categorical_accuracy: 0.9629 - val_loss: 0.1186 - val_categorical_accuracy: 0.9601\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1193 - categorical_accuracy: 0.9618 - val_loss: 0.1160 - val_categorical_accuracy: 0.9633\n",
      "173/173 [==============================] - 111s 644ms/step - loss: 0.1065 - categorical_accuracy: 0.9677\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6422 - categorical_accuracy: 0.5957 - val_loss: 0.3637 - val_categorical_accuracy: 0.8549\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.2454 - categorical_accuracy: 0.9266 - val_loss: 0.1962 - val_categorical_accuracy: 0.9393\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1876 - categorical_accuracy: 0.9459 - val_loss: 0.1658 - val_categorical_accuracy: 0.9440\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1727 - categorical_accuracy: 0.9486 - val_loss: 0.1556 - val_categorical_accuracy: 0.9532\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1643 - categorical_accuracy: 0.9504 - val_loss: 0.1478 - val_categorical_accuracy: 0.9576\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1658 - categorical_accuracy: 0.9511 - val_loss: 0.1512 - val_categorical_accuracy: 0.9543\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1494 - categorical_accuracy: 0.9557 - val_loss: 0.1491 - val_categorical_accuracy: 0.9576\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1599 - categorical_accuracy: 0.9522 - val_loss: 0.1411 - val_categorical_accuracy: 0.9581\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1559 - categorical_accuracy: 0.9538 - val_loss: 0.1523 - val_categorical_accuracy: 0.9534\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1443 - categorical_accuracy: 0.9556 - val_loss: 0.1322 - val_categorical_accuracy: 0.9583\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1485 - categorical_accuracy: 0.9545 - val_loss: 0.1385 - val_categorical_accuracy: 0.9585\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1542 - categorical_accuracy: 0.9532 - val_loss: 0.1309 - val_categorical_accuracy: 0.9588\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1382 - categorical_accuracy: 0.9573 - val_loss: 0.1377 - val_categorical_accuracy: 0.9583\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1389 - categorical_accuracy: 0.9576 - val_loss: 0.1379 - val_categorical_accuracy: 0.9599\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1520 - categorical_accuracy: 0.9543 - val_loss: 0.1326 - val_categorical_accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1412 - categorical_accuracy: 0.9565 - val_loss: 0.1285 - val_categorical_accuracy: 0.9601\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1360 - categorical_accuracy: 0.9591 - val_loss: 0.1291 - val_categorical_accuracy: 0.9619\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1461 - categorical_accuracy: 0.9542 - val_loss: 0.1290 - val_categorical_accuracy: 0.9586\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1398 - categorical_accuracy: 0.9578 - val_loss: 0.1249 - val_categorical_accuracy: 0.9632\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1380 - categorical_accuracy: 0.9561 - val_loss: 0.1362 - val_categorical_accuracy: 0.9568\n",
      "173/173 [==============================] - 111s 641ms/step - loss: 0.1262 - categorical_accuracy: 0.96121:15 - loss: 0.1286 - categorical_ac - ETA: 51s - loss: 0.\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 191s 369ms/step - loss: 0.6985 - categorical_accuracy: 0.4988 - val_loss: 0.6960 - val_categorical_accuracy: 0.5116\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.4953 - val_loss: 0.6965 - val_categorical_accuracy: 0.5063\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6934 - categorical_accuracy: 0.4987 - val_loss: 0.6962 - val_categorical_accuracy: 0.5074\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.6933 - categorical_accuracy: 0.4914 - val_loss: 0.6964 - val_categorical_accuracy: 0.4926\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.4967 - val_loss: 0.6963 - val_categorical_accuracy: 0.5005\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 195s 378ms/step - loss: 0.6933 - categorical_accuracy: 0.4964 - val_loss: 0.6963 - val_categorical_accuracy: 0.4980\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 190s 368ms/step - loss: 0.6932 - categorical_accuracy: 0.5040 - val_loss: 0.6964 - val_categorical_accuracy: 0.5013\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4980 - val_loss: 0.6964 - val_categorical_accuracy: 0.4939\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4933 - val_loss: 0.6963 - val_categorical_accuracy: 0.4969\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.6932 - categorical_accuracy: 0.5016 - val_loss: 0.6964 - val_categorical_accuracy: 0.5007\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4961 - val_loss: 0.6964 - val_categorical_accuracy: 0.4998\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.6932 - categorical_accuracy: 0.4943 - val_loss: 0.6964 - val_categorical_accuracy: 0.4946\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.6932 - categorical_accuracy: 0.5036 - val_loss: 0.6963 - val_categorical_accuracy: 0.4984\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6933 - categorical_accuracy: 0.5008 - val_loss: 0.6963 - val_categorical_accuracy: 0.4991\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4943 - val_loss: 0.6963 - val_categorical_accuracy: 0.4924\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.6932 - categorical_accuracy: 0.5008 - val_loss: 0.6962 - val_categorical_accuracy: 0.5070\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6932 - categorical_accuracy: 0.4972 - val_loss: 0.6962 - val_categorical_accuracy: 0.5047\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4995 - val_loss: 0.6962 - val_categorical_accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "517/516 [==============================] - 188s 365ms/step - loss: 0.6933 - categorical_accuracy: 0.4987 - val_loss: 0.6964 - val_categorical_accuracy: 0.5009\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.6932 - categorical_accuracy: 0.4995 - val_loss: 0.6962 - val_categorical_accuracy: 0.5058\n",
      "173/173 [==============================] - 112s 647ms/step - loss: 0.6932 - categorical_accuracy: 0.5010\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 193s 374ms/step - loss: 0.5519 - categorical_accuracy: 0.6999 - val_loss: 0.3260 - val_categorical_accuracy: 0.9016\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.2470 - categorical_accuracy: 0.9245 - val_loss: 0.1868 - val_categorical_accuracy: 0.9440\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1767 - categorical_accuracy: 0.9450 - val_loss: 0.1583 - val_categorical_accuracy: 0.9478\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1584 - categorical_accuracy: 0.9505 - val_loss: 0.1312 - val_categorical_accuracy: 0.9597\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 367ms/step - loss: 0.1525 - categorical_accuracy: 0.9530 - val_loss: 0.1408 - val_categorical_accuracy: 0.9516\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1544 - categorical_accuracy: 0.9518 - val_loss: 0.1374 - val_categorical_accuracy: 0.9557\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1398 - categorical_accuracy: 0.9553 - val_loss: 0.1222 - val_categorical_accuracy: 0.9579\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 191s 369ms/step - loss: 0.1428 - categorical_accuracy: 0.9535 - val_loss: 0.1138 - val_categorical_accuracy: 0.9615\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1369 - categorical_accuracy: 0.9551 - val_loss: 0.1280 - val_categorical_accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1324 - categorical_accuracy: 0.9570 - val_loss: 0.1267 - val_categorical_accuracy: 0.9566\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1231 - categorical_accuracy: 0.9600 - val_loss: 0.1115 - val_categorical_accuracy: 0.9622\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1310 - categorical_accuracy: 0.9566 - val_loss: 0.1061 - val_categorical_accuracy: 0.9653\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 189s 366ms/step - loss: 0.1212 - categorical_accuracy: 0.9590 - val_loss: 0.1123 - val_categorical_accuracy: 0.9604\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1225 - categorical_accuracy: 0.9599 - val_loss: 0.1039 - val_categorical_accuracy: 0.9653\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1248 - categorical_accuracy: 0.9596 - val_loss: 0.1010 - val_categorical_accuracy: 0.9677\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1168 - categorical_accuracy: 0.9611 - val_loss: 0.1051 - val_categorical_accuracy: 0.9669\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1116 - categorical_accuracy: 0.9643 - val_loss: 0.1158 - val_categorical_accuracy: 0.9597\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1140 - categorical_accuracy: 0.9625 - val_loss: 0.0935 - val_categorical_accuracy: 0.9678\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1088 - categorical_accuracy: 0.9630 - val_loss: 0.0916 - val_categorical_accuracy: 0.9669\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1090 - categorical_accuracy: 0.9633 - val_loss: 0.1031 - val_categorical_accuracy: 0.9650\n",
      "173/173 [==============================] - 111s 640ms/step - loss: 0.1063 - categorical_accuracy: 0.9623\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.4111 - categorical_accuracy: 0.8051 - val_loss: 0.1866 - val_categorical_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1795 - categorical_accuracy: 0.9449 - val_loss: 0.1551 - val_categorical_accuracy: 0.9520\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1558 - categorical_accuracy: 0.9505 - val_loss: 0.1470 - val_categorical_accuracy: 0.9548\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1439 - categorical_accuracy: 0.9565 - val_loss: 0.1311 - val_categorical_accuracy: 0.9566\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1438 - categorical_accuracy: 0.9539 - val_loss: 0.1428 - val_categorical_accuracy: 0.9530\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1329 - categorical_accuracy: 0.9583 - val_loss: 0.1249 - val_categorical_accuracy: 0.9617\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1215 - categorical_accuracy: 0.9582 - val_loss: 0.1079 - val_categorical_accuracy: 0.9630\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1237 - categorical_accuracy: 0.9607 - val_loss: 0.1020 - val_categorical_accuracy: 0.9671\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1241 - categorical_accuracy: 0.9592 - val_loss: 0.1138 - val_categorical_accuracy: 0.9639\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1093 - categorical_accuracy: 0.9652 - val_loss: 0.0967 - val_categorical_accuracy: 0.9668\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1120 - categorical_accuracy: 0.9628 - val_loss: 0.1014 - val_categorical_accuracy: 0.9660\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1117 - categorical_accuracy: 0.9642 - val_loss: 0.0956 - val_categorical_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.1007 - categorical_accuracy: 0.9671 - val_loss: 0.0999 - val_categorical_accuracy: 0.9646\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1023 - categorical_accuracy: 0.9656 - val_loss: 0.0895 - val_categorical_accuracy: 0.9713\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.0958 - categorical_accuracy: 0.9689 - val_loss: 0.0784 - val_categorical_accuracy: 0.9740\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.0866 - categorical_accuracy: 0.9705 - val_loss: 0.0885 - val_categorical_accuracy: 0.9718\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.0894 - categorical_accuracy: 0.9704 - val_loss: 0.1090 - val_categorical_accuracy: 0.9644\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0922 - categorical_accuracy: 0.9711 - val_loss: 0.0845 - val_categorical_accuracy: 0.9736\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.0926 - categorical_accuracy: 0.9695 - val_loss: 0.0694 - val_categorical_accuracy: 0.9762\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.0765 - categorical_accuracy: 0.9743 - val_loss: 0.0716 - val_categorical_accuracy: 0.9778\n",
      "173/173 [==============================] - 110s 635ms/step - loss: 0.0751 - categorical_accuracy: 0.9782\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.6894 - categorical_accuracy: 0.5484 - val_loss: 0.6074 - val_categorical_accuracy: 0.6828\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.3569 - categorical_accuracy: 0.8520 - val_loss: 0.1924 - val_categorical_accuracy: 0.9384\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1962 - categorical_accuracy: 0.9378 - val_loss: 0.1499 - val_categorical_accuracy: 0.9534\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1630 - categorical_accuracy: 0.9486 - val_loss: 0.1373 - val_categorical_accuracy: 0.9565\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1579 - categorical_accuracy: 0.9497 - val_loss: 0.1407 - val_categorical_accuracy: 0.9550\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.1476 - categorical_accuracy: 0.9554 - val_loss: 0.1281 - val_categorical_accuracy: 0.9590\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1393 - categorical_accuracy: 0.9543 - val_loss: 0.1147 - val_categorical_accuracy: 0.9635\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1379 - categorical_accuracy: 0.9568 - val_loss: 0.1262 - val_categorical_accuracy: 0.9603\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1385 - categorical_accuracy: 0.9556 - val_loss: 0.1170 - val_categorical_accuracy: 0.9644\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1326 - categorical_accuracy: 0.9571 - val_loss: 0.1181 - val_categorical_accuracy: 0.9603\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 187s 363ms/step - loss: 0.1269 - categorical_accuracy: 0.9594 - val_loss: 0.1294 - val_categorical_accuracy: 0.9599\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1225 - categorical_accuracy: 0.9615 - val_loss: 0.1027 - val_categorical_accuracy: 0.9651\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1172 - categorical_accuracy: 0.9623 - val_loss: 0.1154 - val_categorical_accuracy: 0.9617\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1169 - categorical_accuracy: 0.9624 - val_loss: 0.1088 - val_categorical_accuracy: 0.9633\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1238 - categorical_accuracy: 0.9598 - val_loss: 0.1083 - val_categorical_accuracy: 0.9653\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1063 - categorical_accuracy: 0.9646 - val_loss: 0.0955 - val_categorical_accuracy: 0.9651\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1075 - categorical_accuracy: 0.9661 - val_loss: 0.1331 - val_categorical_accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1114 - categorical_accuracy: 0.9658 - val_loss: 0.1312 - val_categorical_accuracy: 0.9565\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1002 - categorical_accuracy: 0.9665 - val_loss: 0.0888 - val_categorical_accuracy: 0.9686\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.0996 - categorical_accuracy: 0.9684 - val_loss: 0.0965 - val_categorical_accuracy: 0.9680\n",
      "173/173 [==============================] - 110s 636ms/step - loss: 0.0936 - categorical_accuracy: 0.9701\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.7057 - categorical_accuracy: 0.5450 - val_loss: 0.5657 - val_categorical_accuracy: 0.7166\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.6667 - categorical_accuracy: 0.6007 - val_loss: 0.5156 - val_categorical_accuracy: 0.7999\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.3087 - categorical_accuracy: 0.9024 - val_loss: 0.1867 - val_categorical_accuracy: 0.9406\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.2084 - categorical_accuracy: 0.9297 - val_loss: 0.2155 - val_categorical_accuracy: 0.9350\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1973 - categorical_accuracy: 0.9411 - val_loss: 0.1994 - val_categorical_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1704 - categorical_accuracy: 0.9505 - val_loss: 0.1668 - val_categorical_accuracy: 0.9480\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1747 - categorical_accuracy: 0.9510 - val_loss: 0.1835 - val_categorical_accuracy: 0.9505\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1631 - categorical_accuracy: 0.9496 - val_loss: 0.1765 - val_categorical_accuracy: 0.9523\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1595 - categorical_accuracy: 0.9523 - val_loss: 0.1571 - val_categorical_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1471 - categorical_accuracy: 0.9549 - val_loss: 0.1441 - val_categorical_accuracy: 0.9630\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1452 - categorical_accuracy: 0.9568 - val_loss: 0.1422 - val_categorical_accuracy: 0.9543\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 189s 365ms/step - loss: 0.1620 - categorical_accuracy: 0.9530 - val_loss: 0.1278 - val_categorical_accuracy: 0.9612\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1531 - categorical_accuracy: 0.9536 - val_loss: 0.1356 - val_categorical_accuracy: 0.9612\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1414 - categorical_accuracy: 0.9579 - val_loss: 0.1279 - val_categorical_accuracy: 0.9617\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1361 - categorical_accuracy: 0.9592 - val_loss: 0.1481 - val_categorical_accuracy: 0.9538\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 188s 364ms/step - loss: 0.1414 - categorical_accuracy: 0.9567 - val_loss: 0.1269 - val_categorical_accuracy: 0.9590\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1336 - categorical_accuracy: 0.9603 - val_loss: 0.1903 - val_categorical_accuracy: 0.9449\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 187s 361ms/step - loss: 0.1356 - categorical_accuracy: 0.9571 - val_loss: 0.1261 - val_categorical_accuracy: 0.9622\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 187s 362ms/step - loss: 0.1272 - categorical_accuracy: 0.9596 - val_loss: 0.1206 - val_categorical_accuracy: 0.9632\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 188s 363ms/step - loss: 0.1314 - categorical_accuracy: 0.9587 - val_loss: 0.1164 - val_categorical_accuracy: 0.9642\n",
      "173/173 [==============================] - 110s 638ms/step - loss: 0.1327 - categorical_accuracy: 0.9586\n",
      "Train for 516.6875 steps, validate for 172.21875 steps\n",
      "Epoch 1/20\n",
      "517/516 [==============================] - 190s 368ms/step - loss: 0.5000 - categorical_accuracy: 0.7409 - val_loss: 0.2501 - val_categorical_accuracy: 0.9220\n",
      "Epoch 2/20\n",
      "517/516 [==============================] - 191s 370ms/step - loss: 0.1958 - categorical_accuracy: 0.9354 - val_loss: 0.1513 - val_categorical_accuracy: 0.9503\n",
      "Epoch 3/20\n",
      "517/516 [==============================] - 190s 368ms/step - loss: 0.1706 - categorical_accuracy: 0.9464 - val_loss: 0.1890 - val_categorical_accuracy: 0.9438\n",
      "Epoch 4/20\n",
      "517/516 [==============================] - 217s 420ms/step - loss: 0.1496 - categorical_accuracy: 0.9526 - val_loss: 0.1327 - val_categorical_accuracy: 0.9577\n",
      "Epoch 5/20\n",
      "517/516 [==============================] - 225s 435ms/step - loss: 0.1402 - categorical_accuracy: 0.9553 - val_loss: 0.1366 - val_categorical_accuracy: 0.9550\n",
      "Epoch 6/20\n",
      "517/516 [==============================] - 223s 432ms/step - loss: 0.1348 - categorical_accuracy: 0.9564 - val_loss: 0.1293 - val_categorical_accuracy: 0.9579\n",
      "Epoch 7/20\n",
      "517/516 [==============================] - 217s 420ms/step - loss: 0.1233 - categorical_accuracy: 0.9582 - val_loss: 0.1222 - val_categorical_accuracy: 0.9603\n",
      "Epoch 8/20\n",
      "517/516 [==============================] - 206s 398ms/step - loss: 0.1225 - categorical_accuracy: 0.9579 - val_loss: 0.1173 - val_categorical_accuracy: 0.9579\n",
      "Epoch 9/20\n",
      "517/516 [==============================] - 210s 405ms/step - loss: 0.1241 - categorical_accuracy: 0.9600 - val_loss: 0.1077 - val_categorical_accuracy: 0.9619\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/516 [==============================] - 208s 403ms/step - loss: 0.1062 - categorical_accuracy: 0.9637 - val_loss: 0.0947 - val_categorical_accuracy: 0.9668\n",
      "Epoch 11/20\n",
      "517/516 [==============================] - 211s 409ms/step - loss: 0.1074 - categorical_accuracy: 0.9631 - val_loss: 0.0910 - val_categorical_accuracy: 0.9680\n",
      "Epoch 12/20\n",
      "517/516 [==============================] - 201s 388ms/step - loss: 0.1125 - categorical_accuracy: 0.9619 - val_loss: 0.0971 - val_categorical_accuracy: 0.9650\n",
      "Epoch 13/20\n",
      "517/516 [==============================] - 196s 380ms/step - loss: 0.0933 - categorical_accuracy: 0.9680 - val_loss: 0.0820 - val_categorical_accuracy: 0.9709\n",
      "Epoch 14/20\n",
      "517/516 [==============================] - 210s 407ms/step - loss: 0.0940 - categorical_accuracy: 0.9667 - val_loss: 0.0870 - val_categorical_accuracy: 0.9700\n",
      "Epoch 15/20\n",
      "517/516 [==============================] - 213s 411ms/step - loss: 0.0948 - categorical_accuracy: 0.9674 - val_loss: 0.0781 - val_categorical_accuracy: 0.9740\n",
      "Epoch 16/20\n",
      "517/516 [==============================] - 213s 412ms/step - loss: 0.0802 - categorical_accuracy: 0.9729 - val_loss: 0.1034 - val_categorical_accuracy: 0.9650\n",
      "Epoch 17/20\n",
      "517/516 [==============================] - 193s 373ms/step - loss: 0.0767 - categorical_accuracy: 0.9736 - val_loss: 0.0696 - val_categorical_accuracy: 0.9778\n",
      "Epoch 18/20\n",
      "517/516 [==============================] - 190s 368ms/step - loss: 0.0782 - categorical_accuracy: 0.9741 - val_loss: 0.0655 - val_categorical_accuracy: 0.9792\n",
      "Epoch 19/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0687 - categorical_accuracy: 0.9758 - val_loss: 0.0597 - val_categorical_accuracy: 0.9827\n",
      "Epoch 20/20\n",
      "517/516 [==============================] - 190s 367ms/step - loss: 0.0680 - categorical_accuracy: 0.9765 - val_loss: 0.0590 - val_categorical_accuracy: 0.9810\n",
      "173/173 [==============================] - 111s 642ms/step - loss: 0.0564 - categorical_accuracy: 0.9817\n",
      "Resultado ([0.3, 0.3, 0.3, 0.3], 0.0005) ->[0.08301462591598834, 0.9707857]\n",
      "Resultado ([0.3, 0.3, 0.3, 0.3], 0.001) ->[0.09891370363598097, 0.96842676]\n",
      "Resultado ([0.3, 0.3, 0.3, 0.3], 0.002) ->[0.6930431999223081, 0.50807476]\n",
      "Resultado ([0.3, 0.3, 0.3, 0.3], 0.00025) ->[0.08059742877453652, 0.9727817]\n",
      "Resultado ([0.4, 0.4, 0.4, 0.4], 0.0005) ->[0.10650778054717304, 0.96770096]\n",
      "Resultado ([0.4, 0.4, 0.4, 0.4], 0.001) ->[0.1261667709022416, 0.9611686]\n",
      "Resultado ([0.4, 0.4, 0.4, 0.4], 0.002) ->[0.6931555774170539, 0.500998]\n",
      "Resultado ([0.4, 0.4, 0.4, 0.4], 0.00025) ->[0.10625480001286275, 0.9622573]\n",
      "Resultado ([0.2, 0.2, 0.2, 0.2], 0.0005) ->[0.07509214564554953, 0.97822535]\n",
      "Resultado ([0.2, 0.2, 0.2, 0.2], 0.001) ->[0.09360368248893519, 0.9700599]\n",
      "Resultado ([0.2, 0.2, 0.2, 0.2], 0.002) ->[0.13269870104860362, 0.9586282]\n",
      "Resultado ([0.2, 0.2, 0.2, 0.2], 0.00025) ->[0.056418394388609454, 0.981673]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "def opt_hiper(dropouts,learning_rates):\n",
    "    outs=[]\n",
    "    res = list(itertools.product(dropouts, learning_rates))\n",
    "    for x in res:\n",
    "        model = cnn55D3L2FC(2, 70, 3,x[0],x[1])\n",
    "        \n",
    "        history = model.fit(train_dataset, steps_per_epoch = train_size/BATCH_SIZE,epochs=20, validation_data = val_dataset, validation_steps= val_size/BATCH_SIZE)\n",
    "\n",
    "        var=model.evaluate(test_dataset)\n",
    "        outs.append(\"Resultado \"+ str(x)+\" ->\"+str(var))\n",
    "        \n",
    "    for s in outs:\n",
    "        print (s)\n",
    "    \n",
    "opt_hiper([[0.3,0.3,0.3,0.3],[0.4,0.4,0.4,0.4],[0.2,0.2,0.2,0.2]],[0.0005,0.001,0.002,0.00025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 70, 70, 256)       7168      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70, 70, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 68, 68, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,481,666\n",
      "Trainable params: 2,481,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-24d03fcc22f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "model = cnn55D3L2FC(2, 70, 3,[0.3,0.3,0.3,0.3],0.0005)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
